---
title: "bike_share_analysis"
author: "Sowparnika"
date: "2023-12-13"
output: html_document
---
# Analysis of Bike share Data 2019-2020

## Maximizing the number of annual memberships of a Bike-Share Company 

## *Scenario*

## As a junior data analyst working in the marketing analyst team at Cyclistic, a bike-share company in Chicago, the director of marketing believes the company’s future success depends on maximizing the number of annual memberships. Therefore, their team wants to understand how casual riders and annual members use Cyclistic bikes differently.

###     For the purpose of this case study, the datasets shared by the company are appropriate and will  answer the business questions. The data has been made available by Motivate International Inc. under license. Decided to download data for four quarters.

###     After downloading the bike share data, unzip the files and create a folder on your desktop or Drive to house the files. Use appropriate file-naming conventions.

###     We have used data for four quarters and combined them to a single dataframe for twelve months. The time period for analysis is from April 2019 to March 2020.

### step 1. install the required packages in R for completing the analysis

```{r Install Packages, warning=FALSE}
options(repos = list(CRAN="http://cran.rstudio.com/"))
install.packages("tidyverse")
install.packages("lubridate")
install.packages("ggplot2")
```

### step 2. load the libraries

```{r Load libraries,results='hide', message=FALSE, warning=FALSE}
library(tidyverse)
library(lubridate)
library(ggplot2)
```

### step 3. set your working directory or folder and change the file path according to folder in your computer.

```{r setup}
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_knit$set(root.dir = 'C:/Users/DELL/Documents/S/Google_dataanalytics/case_study_1/data')
```

### step 4. Input the quaterly bikeshare data into respective data frames by using read.csv() function

```{r Read data}
q2_2019 <- read.csv("Divvy_Trips_2019_Q2.csv")
q3_2019 <- read.csv("Divvy_Trips_2019_Q3.csv")
q4_2019 <- read.csv("Divvy_Trips_2019_Q4.csv")
q1_2020 <- read.csv("Divvy_Trips_2020_Q1.csv")
```

### step 5. Explore the dataset, Where relevant, make columns consistent and combine them into a single worksheet. Clean and transform your data to prepare for analysis. We can start by checking column names for consistency.

```{r Column names}
colnames(q3_2019)
colnames(q4_2019)
colnames(q2_2019)
colnames(q1_2020)
```

### step 6. We can see that column names are inconsistent. "q2_2019" has a lot different column names than other quarters. So, to make the column names same we will follow the standard used in "q1_2020". We will use rename() function.

```{r Rename columns, message=FALSE, warning=FALSE, results = "hide"}
(q4_2019 <- rename(q4_2019
                   ,ride_id = trip_id
                   ,rideable_type = bikeid 
                   ,started_at = start_time  
                   ,ended_at = end_time  
                   ,start_station_name = from_station_name 
                   ,start_station_id = from_station_id 
                   ,end_station_name = to_station_name 
                   ,end_station_id = to_station_id 
                   ,member_casual = usertype))

(q3_2019 <- rename(q3_2019
                   ,ride_id = trip_id
                   ,rideable_type = bikeid 
                   ,started_at = start_time  
                   ,ended_at = end_time  
                   ,start_station_name = from_station_name 
                   ,start_station_id = from_station_id 
                   ,end_station_name = to_station_name 
                   ,end_station_id = to_station_id 
                   ,member_casual = usertype))

(q2_2019 <- rename(q2_2019
                   ,ride_id = "X01...Rental.Details.Rental.ID"
                   ,rideable_type = "X01...Rental.Details.Bike.ID"
                   ,tripduration = "X01...Rental.Details.Duration.In.Seconds.Uncapped"
                   ,started_at = "X01...Rental.Details.Local.Start.Time"  
                   ,ended_at = "X01...Rental.Details.Local.End.Time"  
                   ,start_station_name = "X03...Rental.Start.Station.Name" 
                   ,start_station_id = "X03...Rental.Start.Station.ID"
                   ,end_station_name = "X02...Rental.End.Station.Name" 
                   ,end_station_id = "X02...Rental.End.Station.ID"
                   ,member_casual = "User.Type"
                   ,gender = "Member.Gender"
                   ,birthyear = "X05...Member.Details.Member.Birthday.Year"))
```

### Step 7. Re-check column names for consistency. Now, they are consistently named.

```{r Recheck col_names}
colnames(q3_2019)
colnames(q4_2019)
colnames(q2_2019)
colnames(q1_2020)
```

### Step 8. Inspect the data frames and look for incongruities an find data type of each column

```{r Inspect dataframe}
str(q1_2020)
str(q4_2019)
str(q3_2019)
str(q2_2019)
```

### Step 9. Our next aim is to stack all four dataframes over one another into a single dataframe. So, as a first step, we will convert data type of "ride_id" and "rideable_type" columns to character so that they can stack correctly.

```{r Convert datatype, warning=FALSE}
q4_2019 <-  mutate(q4_2019, ride_id = as.character(ride_id)
                   ,rideable_type = as.character(rideable_type)) 
q3_2019 <-  mutate(q3_2019, ride_id = as.character(ride_id)
                   ,rideable_type = as.character(rideable_type)) 
q2_2019 <-  mutate(q2_2019, ride_id = as.character(ride_id)
                   ,rideable_type = as.character(rideable_type))
```

### Step 10. Next, we can stack all four data frames into one big data frame using bind_rows() function

```{r Stack, warning=FALSE}
all_trips <- bind_rows(q2_2019, q3_2019, q4_2019, q1_2020)
```

### Step 11. To make data more consistent, remove lat, long, birthyear, and gender fields as this data was dropped from data collection since 2020

```{r Drop columns, warning=FALSE}
all_trips <- all_trips %>%  
  select(-c(start_lat, start_lng, end_lat, end_lng, birthyear, gender, tripduration))
```

### Step 12. Inspect the new table all_trips that has been created and also re-check column names for consistency

```{r Check}
colnames(all_trips) 
```

### Step 13. Now, we might feel our data is ready for analysis. But, lets re-check again by computing number of rows, column names, using summary() function and cross checking dimensions of data frame. Basically, carefully inspect the new table all_trips that has been created.

```{r Summarize}
colnames(all_trips) 
nrow(all_trips)
dim(all_trips)
head(all_trips)
str(all_trips)
summary(all_trips)
```

###  Step 14. After careful scrutiny, there are a few problems we will need to fix. In the "member_casual" column, there are two names for members ("member" and "Subscriber") and two names for casual riders ("Customer" and "casual"). We will need to consolidate that from four to two labels.First check how many observations fall under each user type.

```{r member_casual}
table(all_trips$member_casual)
```

### Step 15. We can see that there is data under four labels in member type category. So, to change four types of membership to two, we use the following code chunk:

```{r rename member_casual}
all_trips <-  all_trips %>% 
  mutate(member_casual = recode(member_casual
                                ,"Subscriber" = "member"
                                ,"Customer" = "casual"))
```

### Step 16. Again re-run check for number of labels in member_casual using table() function.

```{r Recheck labels}
table(all_trips$member_casual)
```

### Step 17. Now, there are only two labels. Next, Add separate columns for the date, month, day, and year of each ride. This will allow us to aggregate ride data for each month, day, or year. Otherwise, we could only aggregate at the ride level with "ride_id". 

### For that, first we should extract only date into a separate column using as.Date() function. Next, we need to use format() function to extract month, day of the week and year from date column. For more detailed explanation of the function click [here](https://www.statology.org/r-date-format/)

```{r separate date, warning=FALSE}
all_trips$date <- as.Date(all_trips$started_at)
all_trips$month <- format(as.Date(all_trips$date),"%b")
all_trips$day_of_week <- format(as.Date(all_trips$date), "%a")
all_trips$year <- format(as.Date(all_trips$date), "%Y")
```

### Step 18. Create a column called “ride_length.” Calculate the length of each ride by subtracting the column “ended_at” from the column “started_at”. We can do this by using difftime() function to get time in seconds.

```{r ride_length, warning=FALSE}
all_trips$ride_length <- difftime(all_trips$ended_at,all_trips$started_at)
```

### Step 19. Next, let's inspect the structure of the columns in the dataframe "all_trips"

```{r column structure}
str(all_trips)
```

### Step 20. Convert data type of "ride_length" from factor to numeric so that we can run calculations on the data like maximum, mean, average, minimum etc.

```{r convert datatype}
is.factor(all_trips$ride_length)
all_trips$ride_length <- as.numeric(as.character(all_trips$ride_length))
```

### Step 21. Re-check whether datatype has been converted from factor to numeric

```{r Recheck conversion}
is.numeric(all_trips$ride_length)
```

### Step 22. Remove "bad" data. The data frame includes a few hundred entries, when bikes were taken out of docks and checked for quality by company. These values can be identified by negative value in "ride_length". We will create a new version of the data frame (v2) where rows with negative "ride_length" data is being removed.

```{r new all_trips, warning=FALSE}
all_trips_v2 <- all_trips[!(all_trips$start_station_name == "HQ QR" | all_trips$ride_length<0),]
```

### Step 23. Again carefully inspect the structure of the columns. We can see that number of rows have reduced from 3879822 to 3876042. So, there were 3780 rows with negative "ride_length"

```{r Recheck structure}
str(all_trips_v2)
```

### Step 24. Now, we can use the data for twelve months to do further analysis as we have completed a number of cleaning tasks and made it consistent.

###  Next, we can do a descriptive analysis on ride_length (all values in seconds) using following code chunk: 
```{r descriptive analysis}
summary(all_trips_v2$ride_length)
```

### Step 25. Our Aim is to find data about how casual riders use bike share compared to Annual members. So, we compare various parameters like average "ride_length" and number of trips for both categories of users.

```{r Compare}
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual + all_trips_v2$day_of_week, 
          FUN = mean)
```

### Step 26. Notice how the days of the week are out of order. We can fix that by using the following code chunk:

```{r Ordering}
all_trips_v2$day_of_week <- ordered(all_trips_v2$day_of_week,
                                    levels=c("Sun", "Mon", "Tue", 
                                             "Wed", "Thu", "Fri", "Sat"))
```

### Step 27. Now, let's compare the average "ride_length" again by each day for both category of users i.e. annual members and casual users.

```{r Compare ordered}
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual + all_trips_v2$day_of_week,
          FUN = mean)
```

### Step 28. Next, we can analyze and find insights about user type by day of the week. We can first use Mutate() function to creates weekday field using wday(). The, followed by grouping data by user type and day of the week.

### Then, we calculate number of rides and average duration of each ride to sort them by user type and day of the week. We use data pipes to complete all these analysis in the following code chunk:

```{r Insights, warning=FALSE}
 all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>%                        ## creates weekday field using wday()
  group_by(member_casual, weekday) %>%                                        ## groups by user type and weekday
  summarise(number_of_rides = n(), average_duration = mean(ride_length)) %>%  ## calculates the number of rides and average duration
  arrange(member_casual, weekday)   
```

### Step 29. Now, Let's visualize the number of rides v/s average duration plot grouped by rider type. We use ggplot() function to get a column barchart where "dodge" is used to group by "member_casual"

```{r visualize1, warning=FALSE}
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, weekday) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(ride_length)) %>% 
  arrange(member_casual, weekday)  %>% 
  ggplot(aes(x = weekday, y = average_duration, fill = member_casual)) +
  geom_col(position = "dodge")+
  labs(title = "Average duration v/s day of the week")
```

### *1) From the above graph, we can see that average duration of "ridelength" for annual members is much lower than that for casual riders.So, if we target these casual riders, by introducing offers catering to this segment, we can increase annual membership enrollments into the company.*

### *2) Amongst, casual riders, the average duration of "trip_length" is high on Fridays and Sundays. So, ads for memberships can be targeted on these days. Weekend offers might also be considered to increase revenue from casual riders.*

### Step 30. Let's visualize the number of rides v/s weekday plot grouped by user type. Again,we use "dodge" for grouped column plots side by side

```{r Visualize 2, warning=FALSE}
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>%                        ## creates weekday field using wday()
  group_by(member_casual, weekday) %>%                                        ## groups by user type and weekday
  summarise(number_of_rides = n(), average_duration = mean(ride_length)) %>%  ## calculates the number of rides and average duration
  arrange(member_casual, weekday) %>% 
  ggplot(aes(x = weekday, y = number_of_rides, fill = member_casual)) +
  geom_col(position = "dodge")+
  labs(title = "Number of rides v/s day of the week")
```

### *1) From the above graph, it is clear that number of trips by annual members are higher compared to casual riders especially during weekdays. Further analysis needs to be done to determine wether higher number of trips by annual members correspond to home-work commute during weekdays.*

### *2) Again, we can observe  casual riders have taken more number of trips during weekends compared to weekdays. Further analysis needs to be done to determine the reason for an increase in number of trips by casual users during weekend.*

### *3) This graph also suggests the possibility of exploring weekend offers and ads targeting casual riders to convert to annual members.*


### Step 31. Next, we can export a SUMMARY FILE for further analysis. We Create a new csv file that we will use to visualize in Excel, Tableau, or my presentation software. By using write.csv() function, a new file with "all_trips_v2" data is created.

```{r export}
write.csv(all_trips_v2, "C:/Users/DELL/Documents/S/Google_dataanalytics/case_study_1/data/all_trips_final.csv", 
          row.names=FALSE)
```

### Step 32. We also export a summary table from the data analysed in code chunk titled "Insights"

```{r insights export}
counts <- aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual + all_trips_v2$day_of_week, FUN = mean)
write.csv(counts, file = 'C:/Users/DELL/Documents/S/Google_dataanalytics/case_study_1/data/avg_ride_length.csv')
```

### We come to the end of bike-share case study! We have compared the data about casual users and annual members to obtain insights which would help in increasing memberships. Please do leave feedback regarding this analysis like what can be improved or included.